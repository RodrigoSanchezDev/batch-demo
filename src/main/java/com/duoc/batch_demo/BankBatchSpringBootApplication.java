package com.duoc.batch_demo;

import org.springframework.batch.core.Job;
import org.springframework.batch.core.JobParameters;
import org.springframework.batch.core.Step;
import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;
import org.springframework.batch.core.job.builder.JobBuilder;
import org.springframework.batch.core.launch.JobLauncher;
import org.springframework.batch.core.partition.PartitionHandler;
import org.springframework.batch.core.repository.JobRepository;
import org.springframework.batch.core.step.builder.StepBuilder;
import org.springframework.batch.item.ItemProcessor;
import org.springframework.batch.item.ItemReader;
import org.springframework.batch.item.ItemWriter;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.ConfigurableApplicationContext;
import org.springframework.context.annotation.Bean;
import org.springframework.core.task.TaskExecutor;
import org.springframework.jdbc.support.JdbcTransactionManager;

import com.duoc.batch_demo.config.BankDataPartitioner;
import com.duoc.batch_demo.config.PartitionConfig;
import com.duoc.batch_demo.listener.ScalingPerformanceListener;
import com.duoc.batch_demo.model.AnomaliaTransaccion;
import com.duoc.batch_demo.model.Cuenta;
import com.duoc.batch_demo.model.CuentaAnual;
import com.duoc.batch_demo.model.EstadoCuentaAnual;
import com.duoc.batch_demo.model.InteresCalculado;
import com.duoc.batch_demo.model.Transaccion;

@SpringBootApplication
@EnableBatchProcessing
public class BankBatchSpringBootApplication {

    public static void main(String[] args) throws Exception {
        System.out.println("\n===== SISTEMA DE PROCESAMIENTO BANCARIO BATCH CON ESCALAMIENTO PARALELO Y PARTICIONES =====");
        System.out.println("Iniciando procesamiento con 3 hilos paralelos, 4 particiones y chunks de tama√±o 5...\n");
        System.out.println("=== CONFIGURACI√ìN DE ESCALAMIENTO PARALELO Y PARTICIONES ===");
        System.out.println("   üìä Multi-threading: 3-6 hilos por job (l√≥gica intensiva)");
        System.out.println("   üß© Particiones: 1 hilo coordinador por partici√≥n (distribuci√≥n)");
        System.out.println("   üì¶ Tama√±o de chunks: 5 registros optimizado");
        System.out.println("   üõ°Ô∏è  Tolerancia a fallos: Integrada");
        System.out.println("   üéØ SEPARACI√ìN DE RESPONSABILIDADES IMPLEMENTADA");
        System.out.println("");
        System.out.println("üéØ DATASET REAL CONFIGURADO (SEMANA 3 - 1000+ REGISTROS):");
        System.out.println("   üìÅ Transacciones: data/semana_3/transacciones.csv (~1,000 registros)");
        System.out.println("   üìà Monitoreo de rendimiento: Activo");
        System.out.println("   üîÑ Procesamiento distribuido: Habilitado");
        System.out.println("===============================================================================\n");

        // Configurar para no ejecutar autom√°ticamente los jobs
        System.setProperty("spring.batch.job.enabled", "false");

        ConfigurableApplicationContext context = SpringApplication.run(BankBatchSpringBootApplication.class, args);

        try {
            JobLauncher jobLauncher = context.getBean(JobLauncher.class);

            // ============================================
            // EJECUTAR LOS 3 JOBS PRINCIPALES CON DETALLES
            // ============================================
            
            System.out.println("=== EJECUTANDO JOB 1: REPORTE DE TRANSACCIONES DIARIAS ===");
            Job reporteTransaccionesJob = context.getBean("reporteTransaccionesJob", Job.class);
            jobLauncher.run(reporteTransaccionesJob, new JobParameters());

            System.out.println("=== EJECUTANDO PROCESAMIENTO DE ANOMAL√çAS ===");
            Job anomaliasJob = context.getBean("anomaliasJob", Job.class);
            jobLauncher.run(anomaliasJob, new JobParameters());
            // Las anomal√≠as se procesan junto con las transacciones

            System.out.println("\n=== EJECUTANDO JOB 2: C√ÅLCULO DE INTERESES MENSUALES ===");
            Job calculoInteresesJob = context.getBean("calculoInteresesJob", Job.class);
            jobLauncher.run(calculoInteresesJob, new JobParameters());

            System.out.println("=== EJECUTANDO GUARDADO DE DETALLES DE INTERESES ===");
            Job interesesDetalleJob = context.getBean("interesesDetalleJob", Job.class);
            jobLauncher.run(interesesDetalleJob, new JobParameters());

            System.out.println("\n=== EJECUTANDO JOB 3: GENERACI√ìN DE ESTADOS DE CUENTA ANUALES ===");
            Job estadosCuentaAnualesJob = context.getBean("estadosCuentaAnualesJob", Job.class);
            jobLauncher.run(estadosCuentaAnualesJob, new JobParameters());

            System.out.println("=== EJECUTANDO PROCESAMIENTO DE ESTADOS DETALLADOS ===");
            Job estadosDetalleJob = context.getBean("estadosDetalleJob", Job.class);
            jobLauncher.run(estadosDetalleJob, new JobParameters());

            // ============================================
            // NUEVOS JOBS PARA DETECTAR TODAS LAS ANOMAL√çAS
            // ============================================
            System.out.println("\n=== EJECUTANDO DETECCI√ìN AVANZADA DE ANOMAL√çAS EN TRANSACCIONES ===");
            Job deteccionAnomal√≠asAvanzadasJob = context.getBean("deteccionAnomal√≠asAvanzadasJob", Job.class);
            jobLauncher.run(deteccionAnomal√≠asAvanzadasJob, new JobParameters());

            System.out.println("\n=== EJECUTANDO DETECCI√ìN DE DUPLICADOS Y ANOMAL√çAS EN CUENTAS ===");
            Job deteccionAnomal√≠asCuentasJob = context.getBean("deteccionAnomal√≠asCuentasJob", Job.class);
            jobLauncher.run(deteccionAnomal√≠asCuentasJob, new JobParameters());

            // ============================================
            // JOBS PARTICIONADOS - DEMOSTRANDO PARTICIONES EN ACCI√ìN
            // ============================================
            System.out.println("\n=== üß© EJECUTANDO JOBS PARTICIONADOS PARA DEMOSTRAR PARTICIONES ===");
            
            System.out.println("\n=== EJECUTANDO JOB PARTICIONADO: TRANSACCIONES DISTRIBUIDAS ===");
            Job particionesTransaccionesJob = context.getBean("particionesTransaccionesJob", Job.class);
            jobLauncher.run(particionesTransaccionesJob, new JobParameters());

            System.out.println("\n=== EJECUTANDO JOB PARTICIONADO: CUENTAS ANUALES DISTRIBUIDAS ===");
            Job particionesCuentasJob = context.getBean("particionesCuentasJob", Job.class);
            jobLauncher.run(particionesCuentasJob, new JobParameters());

            System.out.println("\n=== EJECUTANDO JOB PARTICIONADO: DETECCI√ìN DE ANOMAL√çAS AVANZADA ===");
            Job particionesAnomaliasJob = context.getBean("particionesAnomaliasJob", Job.class);
            jobLauncher.run(particionesAnomaliasJob, new JobParameters());

            System.out.println("\n===== PROCESAMIENTO BANCARIO PARALELO Y PARTICIONADO COMPLETADO EXITOSAMENTE =====");
            System.out.println("Todos los datos han sido procesados con escalamiento paralelo y particiones en base de datos.");
            System.out.println("\nüìä RESUMEN DE ESCALAMIENTO Y PARTICIONES:");
            System.out.println("   üöÄ 3 hilos de ejecuci√≥n paralela utilizados");
            System.out.println("   üß© 4 particiones autom√°ticas configuradas por job particionado");
            System.out.println("   üì¶ Chunks de tama√±o 25 procesados eficientemente");
            System.out.println("   üõ°Ô∏è  Tolerancia a fallos aplicada en todos los steps");
            System.out.println("   üìà M√©tricas de rendimiento capturadas");
            System.out.println("   üîÑ Procesamiento distribuido habilitado");
            System.out.println("\nüéØ SISTEMA DE DETECCI√ìN AVANZADA DE ANOMAL√çAS (Paralelo + Particionado):");
            System.out.println("   üí∞ Montos negativos y cero detectados en paralelo");
            System.out.println("   üîç Tipos de transacci√≥n inv√°lidos identificados concurrentemente");
            System.out.println("   üìã Registros duplicados encontrados con m√∫ltiples threads");
            System.out.println("   üéÇ Edades fuera de rango detectadas paralelamente");
            System.out.println("   ‚ùì Datos faltantes identificados con escalamiento");
            System.out.println("\nüóÑÔ∏è  BASE DE DATOS:");
            System.out.println("   Conectar a la base de datos para revisar los resultados del procesamiento.");
            System.out.println("   üìã Tablas: transacciones, cuentas, cuentas_anuales,");
            System.out.println("            intereses_calculados, anomalias_transacciones, estados_cuenta_anuales");
            System.out.println("   üìä Logs de escalamiento y particiones disponibles arriba para an√°lisis.\n");

        } catch (Exception e) {
            System.err.println("‚ùå Error durante el procesamiento: " + e.getMessage());
            e.printStackTrace();
        } finally {
            // Informaci√≥n final
            System.out.println("‚úÖ Aplicaci√≥n completada. Los datos permanecen en base de datos para revisi√≥n.");
            System.out.println("üß© Sistema con particiones implementado exitosamente.");
            
            // Cierre autom√°tico del contexto
            System.out.println("\nüîÑ Cerrando aplicaci√≥n autom√°ticamente en 3 segundos...");
            try {
                Thread.sleep(3000); // 3 segundos para ver el mensaje
            } catch (InterruptedException ie) {
                Thread.currentThread().interrupt();
            }
            
            // Cierre limpio del contexto de Spring
            if (context != null) {
                context.close();
            }
            
            // Finalizar la aplicaci√≥n
            System.exit(0);
        }
    }

    // ============================================
    // CONFIGURACI√ìN DE JOBS Y STEPS
    // ============================================

    // ============================================
    // JOB 1: REPORTE DE TRANSACCIONES DIARIAS CON ESCALAMIENTO PARALELO
    // ============================================
    @Bean
    public Step transaccionesStep(JobRepository jobRepository,
                                 JdbcTransactionManager transactionManager,
                                 ItemReader<Transaccion> transaccionReader,
                                 ItemProcessor<Transaccion, Transaccion> transaccionItemProcessor,
                                 ItemWriter<Transaccion> transaccionWriter,
                                 org.springframework.retry.RetryPolicy transaccionesRetryPolicy,
                                 org.springframework.batch.core.step.skip.SkipPolicy transaccionesSkipPolicy,
                                 org.springframework.batch.core.StepExecutionListener faultToleranceListener,
                                 @Qualifier("transactionTaskExecutor") TaskExecutor transactionTaskExecutor,
                                 @Qualifier("optimizedChunkSize") Integer chunkSize) {
        
        System.out.println("=== CONFIGURANDO STEP TRANSACCIONES CON ESCALAMIENTO PARALELO ===");
        System.out.println("   TaskExecutor: " + transactionTaskExecutor.getClass().getSimpleName());
        System.out.println("   Chunk Size: " + chunkSize + " registros");
        System.out.println("   Hilos paralelos: 3");
        System.out.println("   Tolerancia a fallos integrada");
        
        return new StepBuilder("transaccionesStep", jobRepository)
                .<Transaccion, Transaccion>chunk(chunkSize, transactionManager)  // Chunk size 5
                .reader(transaccionReader)
                .processor(transaccionItemProcessor)
                .writer(transaccionWriter)
                // Escalamiento paralelo con 3 hilos
                .taskExecutor(transactionTaskExecutor)
                // üõ°Ô∏è TOLERANCIA A FALLOS PARA TRANSACCIONES PRINCIPALES
                .faultTolerant()
                .retryPolicy(transaccionesRetryPolicy)
                .skipPolicy(transaccionesSkipPolicy)
                .listener(faultToleranceListener)
                .build();
    }

    @Bean
    public Job reporteTransaccionesJob(JobRepository jobRepository, Step transaccionesStep) {
        return new JobBuilder("reporteTransaccionesJob", jobRepository)
                .start(transaccionesStep)
                .build();
    }

    // ============================================
    // JOB 2: C√ÅLCULO DE INTERESES MENSUALES CON ESCALAMIENTO PARALELO
    // ============================================
    @Bean
    public Step interesesStep(JobRepository jobRepository,
                             JdbcTransactionManager transactionManager,
                             ItemReader<Cuenta> cuentaReader,
                             ItemProcessor<Cuenta, Cuenta> interesesItemProcessor,
                             ItemWriter<Cuenta> cuentaWriter,
                             org.springframework.retry.RetryPolicy cuentasRetryPolicy,
                             org.springframework.batch.core.step.skip.SkipPolicy cuentasSkipPolicy,
                             org.springframework.batch.core.StepExecutionListener faultToleranceListener,
                             @Qualifier("accountTaskExecutor") TaskExecutor accountTaskExecutor,
                             @Qualifier("optimizedChunkSize") Integer chunkSize) {
        
        System.out.println("=== CONFIGURANDO STEP INTERESES CON ESCALAMIENTO PARALELO ===");
        System.out.println("   TaskExecutor: " + accountTaskExecutor.getClass().getSimpleName());
        System.out.println("   Chunk Size: " + chunkSize + " registros");
        System.out.println("   Hilos paralelos: 3 (escalamiento hasta 4)");
        System.out.println("   Tolerancia a fallos para cuentas");
        
        return new StepBuilder("interesesStep", jobRepository)
                .<Cuenta, Cuenta>chunk(chunkSize, transactionManager)  // Chunk size 5
                .reader(cuentaReader)
                .processor(interesesItemProcessor)
                .writer(cuentaWriter)
                // Escalamiento paralelo con balanceamiento din√°mico
                .taskExecutor(accountTaskExecutor)
                // üõ°Ô∏è TOLERANCIA A FALLOS PARA C√ÅLCULO DE INTERESES
                .faultTolerant()
                .retryPolicy(cuentasRetryPolicy)     // M√°s conservador para cuentas
                .skipPolicy(cuentasSkipPolicy)
                .listener(faultToleranceListener)
                .build();
    }

    @Bean
    public Job calculoInteresesJob(JobRepository jobRepository, Step interesesStep) {
        return new JobBuilder("calculoInteresesJob", jobRepository)
                .start(interesesStep)
                .build();
    }

    // ============================================
    // JOB 3: GENERACI√ìN DE ESTADOS DE CUENTA ANUALES
    // ============================================
    @Bean
    public Step cuentasAnualesStep(JobRepository jobRepository,
                                  JdbcTransactionManager transactionManager,
                                  ItemReader<CuentaAnual> cuentaAnualReader,
                                  ItemProcessor<CuentaAnual, CuentaAnual> cuentaAnualItemProcessor,
                                  ItemWriter<CuentaAnual> cuentaAnualWriter) {
        return new StepBuilder("cuentasAnualesStep", jobRepository)
                .<CuentaAnual, CuentaAnual>chunk(10, transactionManager)
                .reader(cuentaAnualReader)
                .processor(cuentaAnualItemProcessor)
                .writer(cuentaAnualWriter)
                .build();
    }

    @Bean
    public Job estadosCuentaAnualesJob(JobRepository jobRepository, Step cuentasAnualesStep) {
        return new JobBuilder("estadosCuentaAnualesJob", jobRepository)
                .start(cuentasAnualesStep)
                .build();
    }

    // ============================================
    // JOBS ADICIONALES PARA DETALLES
    // ============================================

    // Job para procesar detalles de intereses calculados
    @Bean
    public Step interesesDetalleStep(JobRepository jobRepository,
                                   JdbcTransactionManager transactionManager,
                                   ItemReader<Cuenta> cuentaReader,
                                   ItemProcessor<Cuenta, InteresCalculado> interesCalculadoItemProcessor,
                                   ItemWriter<InteresCalculado> interesCalculadoWriter) {
        return new StepBuilder("interesesDetalleStep", jobRepository)
                .<Cuenta, InteresCalculado>chunk(10, transactionManager)
                .reader(cuentaReader)
                .processor(interesCalculadoItemProcessor)
                .writer(interesCalculadoWriter)
                .build();
    }

    @Bean
    public Job interesesDetalleJob(JobRepository jobRepository, Step interesesDetalleStep) {
        return new JobBuilder("interesesDetalleJob", jobRepository)
                .start(interesesDetalleStep)
                .build();
    }

    // Job para procesar estados de cuenta detallados
    @Bean
    public Step estadosDetalleStep(JobRepository jobRepository,
                                 JdbcTransactionManager transactionManager,
                                 ItemReader<CuentaAnual> cuentaAnualReader,
                                 ItemProcessor<CuentaAnual, EstadoCuentaAnual> estadoCuentaAnualItemProcessor,
                                 ItemWriter<EstadoCuentaAnual> estadoCuentaAnualWriter) {
        return new StepBuilder("estadosDetalleStep", jobRepository)
                .<CuentaAnual, EstadoCuentaAnual>chunk(10, transactionManager)
                .reader(cuentaAnualReader)
                .processor(estadoCuentaAnualItemProcessor)
                .writer(estadoCuentaAnualWriter)
                .build();
    }

    @Bean
    public Job estadosDetalleJob(JobRepository jobRepository, Step estadosDetalleStep) {
        return new JobBuilder("estadosDetalleJob", jobRepository)
                .start(estadosDetalleStep)
                .build();
    }

    // Job para procesar anomal√≠as de transacciones
    @Bean
    public Step anomaliasStep(JobRepository jobRepository,
                             JdbcTransactionManager transactionManager,
                             ItemReader<Transaccion> anomaliaTransaccionReader,
                             ItemProcessor<Transaccion, AnomaliaTransaccion> simpleAnomaliaProcessor,
                             ItemWriter<AnomaliaTransaccion> anomaliaTransaccionWriter) {
        return new StepBuilder("anomaliasStep", jobRepository)
                .<Transaccion, AnomaliaTransaccion>chunk(10, transactionManager)
                .reader(anomaliaTransaccionReader)
                .processor(simpleAnomaliaProcessor)
                .writer(anomaliaTransaccionWriter)
                .build();
    }

    @Bean
    public Job anomaliasJob(JobRepository jobRepository, Step anomaliasStep) {
        return new JobBuilder("anomaliasJob", jobRepository)
                .start(anomaliasStep)
                .build();
    }

    // ============================================
    // JOBS AVANZADOS PARA DETECCI√ìN DE ANOMAL√çAS CON POL√çTICAS DE REINTENTO Y OMISI√ìN
    // ============================================
    
    // Step para detectar TODAS las anomal√≠as en transacciones con ESCALAMIENTO PARALELO
    @Bean
    public Step deteccionAnomal√≠asAvanzadasStep(JobRepository jobRepository,
                                               JdbcTransactionManager transactionManager,
                                               ItemReader<Transaccion> todasLasTransaccionesReader,
                                               ItemProcessor<Transaccion, java.util.List<AnomaliaTransaccion>> detectarAnomal√≠asLegacyProcessor,
                                               org.springframework.batch.item.ItemWriter<java.util.List<AnomaliaTransaccion>> anomaliaListWriter,
                                               org.springframework.retry.RetryPolicy transaccionesRetryPolicy,
                                               org.springframework.batch.core.step.skip.SkipPolicy transaccionesSkipPolicy,
                                               org.springframework.batch.core.StepExecutionListener faultToleranceListener,
                                               @Qualifier("anomalyTaskExecutor") TaskExecutor anomalyTaskExecutor,
                                               @Qualifier("optimizedChunkSize") Integer chunkSize) {
        
        System.out.println("=== CONFIGURANDO DETECCI√ìN ANOMAL√çAS CON ESCALAMIENTO PARALELO ===");
        System.out.println("   TaskExecutor: " + anomalyTaskExecutor.getClass().getSimpleName());
        System.out.println("   Chunk Size: " + chunkSize + " registros");
        System.out.println("   Hilos paralelos: 3 (escalamiento hasta 6)");
        System.out.println("   Detecci√≥n inteligente de anomal√≠as");
        
        return new StepBuilder("deteccionAnomal√≠asAvanzadasStep", jobRepository)
                .<Transaccion, java.util.List<AnomaliaTransaccion>>chunk(chunkSize, transactionManager)
                .reader(todasLasTransaccionesReader)
                .processor(detectarAnomal√≠asLegacyProcessor)
                .writer(anomaliaListWriter)
                // Escalamiento paralelo para an√°lisis de anomal√≠as
                .taskExecutor(anomalyTaskExecutor)
                // üõ°Ô∏è POL√çTICAS PERSONALIZADAS DE TOLERANCIA A FALLOS
                .faultTolerant()
                .retryPolicy(transaccionesRetryPolicy) // Pol√≠tica de reintento personalizada
                .skipPolicy(transaccionesSkipPolicy)   // Pol√≠tica de omisi√≥n inteligente
                .listener(faultToleranceListener)      // Monitoreo y logging avanzado
                .build();
    }

    @Bean
    public Job deteccionAnomal√≠asAvanzadasJob(JobRepository jobRepository, Step deteccionAnomal√≠asAvanzadasStep) {
        return new JobBuilder("deteccionAnomal√≠asAvanzadasJob", jobRepository)
                .start(deteccionAnomal√≠asAvanzadasStep)
                .build();
    }

    // Step para detectar anomal√≠as y duplicados en cuentas
    @Bean
    public Step deteccionAnomal√≠asCuentasStep(JobRepository jobRepository,
                                             JdbcTransactionManager transactionManager,
                                             ItemReader<Cuenta> todasLasCuentasReader,
                                             ItemProcessor<Cuenta, java.util.List<AnomaliaTransaccion>> detectarAnomaliasCuentasProcessor,
                                             org.springframework.batch.item.ItemWriter<java.util.List<AnomaliaTransaccion>> anomaliaListWriter,
                                             org.springframework.retry.RetryPolicy cuentasRetryPolicy,
                                             org.springframework.batch.core.step.skip.SkipPolicy cuentasSkipPolicy,
                                             org.springframework.batch.core.StepExecutionListener faultToleranceListener) {
        return new StepBuilder("deteccionAnomal√≠asCuentasStep", jobRepository)
                .<Cuenta, java.util.List<AnomaliaTransaccion>>chunk(5, transactionManager)
                .reader(todasLasCuentasReader)
                .processor(detectarAnomaliasCuentasProcessor)
                .writer(anomaliaListWriter)
                // üõ°Ô∏è POL√çTICAS PERSONALIZADAS PARA CUENTAS (M√ÅS ESTRICTAS)
                .faultTolerant()
                .retryPolicy(cuentasRetryPolicy)     // Reintentos m√°s conservadores
                .skipPolicy(cuentasSkipPolicy)       // Omisiones m√°s estrictas
                .listener(faultToleranceListener)    // Monitoreo detallado
                .build();
    }

    @Bean
    public Job deteccionAnomal√≠asCuentasJob(JobRepository jobRepository, Step deteccionAnomal√≠asCuentasStep) {
        return new JobBuilder("deteccionAnomal√≠asCuentasJob", jobRepository)
                .start(deteccionAnomal√≠asCuentasStep)
                .build();
    }

    // ============================================
    // JOBS CON PARTICIONES - NUEVA FUNCIONALIDAD
    // ============================================
    
    /**
     * Step worker (esclavo) para procesamiento particionado de transacciones.
     * Este step procesa una partici√≥n espec√≠fica de transacciones.
     */
    @Bean
    public Step partitionedTransaccionWorkerStep(JobRepository jobRepository,
                                                  JdbcTransactionManager transactionManager,
                                                  ItemReader<Transaccion> partitionedTransaccionReader,
                                                  ItemProcessor<Transaccion, Transaccion> transaccionItemProcessor,
                                                  ItemWriter<Transaccion> transaccionWriter,
                                                  ScalingPerformanceListener scalingPerformanceListener,
                                                  @Qualifier("optimizedChunkSize") Integer chunkSize) {
        
        System.out.println("‚öôÔ∏è  Configurando Worker Step para Transacciones Particionadas");
        System.out.println("   ‚Ä¢ Chunk Size: " + chunkSize);
        System.out.println("   ‚Ä¢ Listener: PartitionPerformanceListener activo");
        
        return new StepBuilder("partitionedTransaccionWorkerStep", jobRepository)
                .<Transaccion, Transaccion>chunk(chunkSize, transactionManager)
                .reader(partitionedTransaccionReader) // Se resuelve din√°micamente por @StepScope
                .processor(transaccionItemProcessor)
                .writer(transaccionWriter)
                .listener(scalingPerformanceListener)
                .build();
    }
    
    /**
     * Step maestro para procesamiento particionado de transacciones.
     * Coordina m√∫ltiples particiones utilizando el partitioner y handler.
     */
    @Bean
    public Step partitionedTransaccionMasterStep(JobRepository jobRepository,
                                                  BankDataPartitioner bankDataPartitioner,
                                                  @Qualifier("partitionCoordinatorTaskExecutor") TaskExecutor coordinatorTaskExecutor,
                                                  Step partitionedTransaccionWorkerStep) {
        
        System.out.println("üéØ Configurando Master Step para Transacciones Particionadas:");
        System.out.println("   ‚Ä¢ Partitioner: BankDataPartitioner");
        System.out.println("   ‚Ä¢ Handler: PartitionCoordinator (4 particiones)");
        System.out.println("   ‚Ä¢ Worker: partitionedTransaccionWorkerStep (SIN multi-threading interno)");
        System.out.println("   ‚Ä¢ Estrategia: DISTRIBUCI√ìN PURA");
        
        // Crear PartitionHandler inline con coordinator simple
        PartitionHandler partitionHandler = PartitionConfig.createTransactionPartitionHandler(coordinatorTaskExecutor, partitionedTransaccionWorkerStep);
        
        return new StepBuilder("partitionedTransaccionMasterStep", jobRepository)
                .partitioner("partitionedTransaccionWorkerStep", bankDataPartitioner)
                .partitionHandler(partitionHandler)
                .step(partitionedTransaccionWorkerStep)
                .build();
    }
    
    /**
     * Job para procesamiento de transacciones usando particiones.
     */
    @Bean
    public Job particionesTransaccionesJob(JobRepository jobRepository, 
                                           Step partitionedTransaccionMasterStep) {
        System.out.println("\nüöÄ CREANDO JOB PARTICIONADO: TRANSACCIONES DISTRIBUIDAS");
        System.out.println("   üìä Estrategia: 4 particiones autom√°ticas por rango de ID");
        System.out.println("   üîÑ TaskExecutor: partitionCoordinatorTaskExecutor (1 hilo por partition)");
        System.out.println("   üéØ Procesamiento: SECUENCIAL dentro de cada partici√≥n");
        System.out.println("   üìà Escalabilidad: Distribuci√≥n geogr√°fica/temporal");
        
        return new JobBuilder("particionesTransaccionesJob", jobRepository)
                .start(partitionedTransaccionMasterStep)
                .build();
    }
    
    /**
     * Step worker para procesamiento particionado de cuentas.
     */
    @Bean
    public Step partitionedCuentaWorkerStep(JobRepository jobRepository,
                                           JdbcTransactionManager transactionManager,
                                           ItemReader<Cuenta> partitionedCuentaReader,
                                           ItemProcessor<Cuenta, Cuenta> interesesItemProcessor,
                                           ItemWriter<Cuenta> cuentaWriter,
                                           ScalingPerformanceListener scalingPerformanceListener,
                                           @Qualifier("optimizedChunkSize") Integer chunkSize) {
        
        System.out.println("‚öôÔ∏è  Configurando Worker Step para Cuentas Particionadas");
        
        return new StepBuilder("partitionedCuentaWorkerStep", jobRepository)
                .<Cuenta, Cuenta>chunk(chunkSize, transactionManager)
                .reader(partitionedCuentaReader) // Se resuelve din√°micamente por @StepScope
                .processor(interesesItemProcessor)
                .writer(cuentaWriter)
                .listener(scalingPerformanceListener)
                .build();
    }
    
    /**
     * Step maestro para procesamiento particionado de cuentas.
     */
    @Bean
    public Step partitionedCuentaMasterStep(JobRepository jobRepository,
                                           BankDataPartitioner bankDataPartitioner,
                                           @Qualifier("partitionCoordinatorTaskExecutor") TaskExecutor coordinatorTaskExecutor,
                                           Step partitionedCuentaWorkerStep) {
        
        System.out.println("üéØ Configurando Master Step para Cuentas Particionadas:");
        System.out.println("   ‚Ä¢ Handler: PartitionCoordinator (3 particiones)");
        System.out.println("   ‚Ä¢ Estrategia: DISTRIBUCI√ìN PURA SIN multi-threading interno");
        
        // Crear PartitionHandler inline con coordinator simple
        PartitionHandler partitionHandler = PartitionConfig.createAccountPartitionHandler(coordinatorTaskExecutor, partitionedCuentaWorkerStep);
        
        return new StepBuilder("partitionedCuentaMasterStep", jobRepository)
                .partitioner("partitionedCuentaWorkerStep", bankDataPartitioner)
                .partitionHandler(partitionHandler)
                .step(partitionedCuentaWorkerStep)
                .build();
    }
    
    /**
     * Job para procesamiento de cuentas usando particiones.
     */
    @Bean
    public Job particionesCuentasJob(JobRepository jobRepository, 
                                    Step partitionedCuentaMasterStep) {
        System.out.println("üöÄ CREANDO JOB PARTICIONADO: CUENTAS ANUALES DISTRIBUIDAS");
        System.out.println("   ‚öôÔ∏è Sistema de Particiones Activo");
        System.out.println("   üìä Distribuci√≥n: 3 Particiones (SIN multi-threading interno)");
        System.out.println("   üéØ Estrategia: DISTRIBUCI√ìN GEOGR√ÅFICA O TEMPORAL");
        System.out.println("   üíæ Escalable para millones de registros");
        System.out.println("   -------------------------------------------");
        
        return new JobBuilder("particionesCuentasJob", jobRepository)
                .start(partitionedCuentaMasterStep)
                .build();
    }
    
    /**
     * Step worker para detecci√≥n particionada de anomal√≠as.
     */
    @Bean
    public Step partitionedAnomaliaWorkerStep(JobRepository jobRepository,
                                             JdbcTransactionManager transactionManager,
                                             ItemReader<Transaccion> partitionedAnomaliaTransaccionReader,
                                             ItemProcessor<Transaccion, java.util.List<AnomaliaTransaccion>> detectarAnomal√≠asLegacyProcessor,
                                             org.springframework.batch.item.ItemWriter<java.util.List<AnomaliaTransaccion>> anomaliaListWriter,
                                             ScalingPerformanceListener scalingPerformanceListener) {
        
        System.out.println("üö® Configurando Worker Step para Anomal√≠as Particionadas");
        
        return new StepBuilder("partitionedAnomaliaWorkerStep", jobRepository)
                .<Transaccion, java.util.List<AnomaliaTransaccion>>chunk(3, transactionManager) // Chunks peque√±os para anomal√≠as
                .reader(partitionedAnomaliaTransaccionReader) // Se resuelve din√°micamente por @StepScope
                .processor(detectarAnomal√≠asLegacyProcessor)
                .writer(anomaliaListWriter)
                .listener(scalingPerformanceListener)
                .build();
    }
    
    /**
     * Step maestro para detecci√≥n particionada de anomal√≠as.
     */
    @Bean
    public Step partitionedAnomaliaMasterStep(JobRepository jobRepository,
                                             BankDataPartitioner bankDataPartitioner,
                                             @Qualifier("partitionCoordinatorTaskExecutor") TaskExecutor coordinatorTaskExecutor,
                                             Step partitionedAnomaliaWorkerStep) {
        
        System.out.println("üéØ Configurando Master Step para Anomal√≠as Particionadas:");
        System.out.println("   ‚Ä¢ Handler: PartitionCoordinator (6 particiones)");
        System.out.println("   ‚Ä¢ Estrategia: DISTRIBUCI√ìN POR TIPO DE ANOMAL√çA");
        
        // Crear PartitionHandler inline con coordinator simple
        PartitionHandler partitionHandler = PartitionConfig.createAnomalyPartitionHandler(coordinatorTaskExecutor, partitionedAnomaliaWorkerStep);
        
        return new StepBuilder("partitionedAnomaliaMasterStep", jobRepository)
                .partitioner("partitionedAnomaliaWorkerStep", bankDataPartitioner)
                .partitionHandler(partitionHandler)
                .step(partitionedAnomaliaWorkerStep)
                .build();
    }
    
    /**
     * Job para detecci√≥n de anomal√≠as usando particiones.
     */
    @Bean
    public Job particionesAnomaliasJob(JobRepository jobRepository, 
                                      Step partitionedAnomaliaMasterStep) {
        System.out.println("üöÄ CREANDO JOB PARTICIONADO: DETECCI√ìN DE ANOMAL√çAS AVANZADA");
        System.out.println("   üö® Sistema de Detecci√≥n Distribuido");
        System.out.println("   üìä Distribuci√≥n: 6 Particiones (SIN multi-threading interno)");
        System.out.println("   üéØ Estrategia: DISTRIBUCI√ìN POR TIPO DE ANOMAL√çA");
        System.out.println("   üîç Escalable para an√°lisis masivos de transacciones");
        System.out.println("   -------------------------------------------");
        
        return new JobBuilder("particionesAnomaliasJob", jobRepository)
                .start(partitionedAnomaliaMasterStep)
                .build();
    }
}
