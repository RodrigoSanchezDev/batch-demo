package com.duoc.batch_demo;

import org.springframework.batch.core.Job;
import org.springframework.batch.core.Step;
import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;
import org.springframework.batch.core.job.builder.JobBuilder;
import org.springframework.batch.core.partition.PartitionHandler;
import org.springframework.batch.core.repository.JobRepository;
import org.springframework.batch.core.step.builder.StepBuilder;
import org.springframework.batch.item.ItemProcessor;
import org.springframework.batch.item.ItemReader;
import org.springframework.batch.item.ItemWriter;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.annotation.Bean;
import org.springframework.core.task.TaskExecutor;
import org.springframework.jdbc.support.JdbcTransactionManager;

import com.duoc.batch_demo.config.BankDataPartitioner;
import com.duoc.batch_demo.config.PartitionConfig;
import com.duoc.batch_demo.listener.ScalingPerformanceListener;
import com.duoc.batch_demo.model.AnomaliaTransaccion;
import com.duoc.batch_demo.model.Cuenta;
import com.duoc.batch_demo.model.CuentaAnual;
import com.duoc.batch_demo.model.EstadoCuentaAnual;
import com.duoc.batch_demo.model.InteresCalculado;
import com.duoc.batch_demo.model.Transaccion;

@SpringBootApplication
@EnableBatchProcessing
public class BankBatchSpringBootApplication {

    public static void main(String[] args) throws Exception {
        System.out.println("\n==============================================");
        System.out.println("üè¶ SISTEMA BANCARIO BATCH + BFFs INICIANDO...");
        System.out.println("==============================================");
        System.out.println("üìä Modo: Servidor API (BFFs habilitados)");
        System.out.println("üåê API Web BFF: http://localhost:8080/api/web/");
        System.out.println("ÔøΩ API Mobile BFF: http://localhost:8080/api/mobile/");
        System.out.println("ÔøΩ API ATM BFF: http://localhost:8080/api/atm/");
        System.out.println("ÔøΩ Documentaci√≥n: http://localhost:8080/swagger-ui.html");
        System.out.println("==============================================");

        // Configurar para no ejecutar autom√°ticamente los jobs
        System.setProperty("spring.batch.job.enabled", "false");

        SpringApplication.run(BankBatchSpringBootApplication.class, args);
        
        System.out.println("\nüöÄ Servidor iniciado exitosamente!");
        System.out.println("üì° Escuchando en puerto 8080...");
        System.out.println("üí° Presiona Ctrl+C para detener el servidor");
        System.out.println("==============================================");
    }

    // ============================================
    // CONFIGURACI√ìN DE JOBS Y STEPS
    // ============================================

    // ============================================
    // JOB 1: REPORTE DE TRANSACCIONES DIARIAS CON ESCALAMIENTO PARALELO
    // ============================================
    @Bean
    public Step transaccionesStep(JobRepository jobRepository,
                                 JdbcTransactionManager transactionManager,
                                 ItemReader<Transaccion> transaccionReader,
                                 ItemProcessor<Transaccion, Transaccion> transaccionItemProcessor,
                                 ItemWriter<Transaccion> transaccionWriter,
                                 org.springframework.retry.RetryPolicy transaccionesRetryPolicy,
                                 org.springframework.batch.core.step.skip.SkipPolicy transaccionesSkipPolicy,
                                 org.springframework.batch.core.StepExecutionListener faultToleranceListener,
                                 @Qualifier("transactionTaskExecutor") TaskExecutor transactionTaskExecutor,
                                 @Qualifier("optimizedChunkSize") Integer chunkSize) {
        
        System.out.println("=== CONFIGURANDO STEP TRANSACCIONES CON ESCALAMIENTO PARALELO ===");
        System.out.println("   TaskExecutor: " + transactionTaskExecutor.getClass().getSimpleName());
        System.out.println("   Chunk Size: " + chunkSize + " registros");
        System.out.println("   Hilos paralelos: 3");
        System.out.println("   Tolerancia a fallos integrada");
        
        return new StepBuilder("transaccionesStep", jobRepository)
                .<Transaccion, Transaccion>chunk(chunkSize, transactionManager)  // Chunk size 5
                .reader(transaccionReader)
                .processor(transaccionItemProcessor)
                .writer(transaccionWriter)
                // Escalamiento paralelo con 3 hilos
                .taskExecutor(transactionTaskExecutor)
                // üõ°Ô∏è TOLERANCIA A FALLOS PARA TRANSACCIONES PRINCIPALES
                .faultTolerant()
                .retryPolicy(transaccionesRetryPolicy)
                .skipPolicy(transaccionesSkipPolicy)
                .listener(faultToleranceListener)
                .build();
    }

    @Bean
    public Job reporteTransaccionesJob(JobRepository jobRepository, Step transaccionesStep) {
        return new JobBuilder("reporteTransaccionesJob", jobRepository)
                .start(transaccionesStep)
                .build();
    }

    // ============================================
    // JOB 2: C√ÅLCULO DE INTERESES MENSUALES CON ESCALAMIENTO PARALELO
    // ============================================
    @Bean
    public Step interesesStep(JobRepository jobRepository,
                             JdbcTransactionManager transactionManager,
                             ItemReader<Cuenta> cuentaReader,
                             ItemProcessor<Cuenta, Cuenta> interesesItemProcessor,
                             ItemWriter<Cuenta> cuentaWriter,
                             org.springframework.retry.RetryPolicy cuentasRetryPolicy,
                             org.springframework.batch.core.step.skip.SkipPolicy cuentasSkipPolicy,
                             org.springframework.batch.core.StepExecutionListener faultToleranceListener,
                             @Qualifier("accountTaskExecutor") TaskExecutor accountTaskExecutor,
                             @Qualifier("optimizedChunkSize") Integer chunkSize) {
        
        System.out.println("=== CONFIGURANDO STEP INTERESES CON ESCALAMIENTO PARALELO ===");
        System.out.println("   TaskExecutor: " + accountTaskExecutor.getClass().getSimpleName());
        System.out.println("   Chunk Size: " + chunkSize + " registros");
        System.out.println("   Hilos paralelos: 3 (escalamiento hasta 4)");
        System.out.println("   Tolerancia a fallos para cuentas");
        
        return new StepBuilder("interesesStep", jobRepository)
                .<Cuenta, Cuenta>chunk(chunkSize, transactionManager)  // Chunk size 5
                .reader(cuentaReader)
                .processor(interesesItemProcessor)
                .writer(cuentaWriter)
                // Escalamiento paralelo con balanceamiento din√°mico
                .taskExecutor(accountTaskExecutor)
                // üõ°Ô∏è TOLERANCIA A FALLOS PARA C√ÅLCULO DE INTERESES
                .faultTolerant()
                .retryPolicy(cuentasRetryPolicy)     // M√°s conservador para cuentas
                .skipPolicy(cuentasSkipPolicy)
                .listener(faultToleranceListener)
                .build();
    }

    @Bean
    public Job calculoInteresesJob(JobRepository jobRepository, Step interesesStep) {
        return new JobBuilder("calculoInteresesJob", jobRepository)
                .start(interesesStep)
                .build();
    }

    // ============================================
    // JOB 3: GENERACI√ìN DE ESTADOS DE CUENTA ANUALES
    // ============================================
    @Bean
    public Step cuentasAnualesStep(JobRepository jobRepository,
                                  JdbcTransactionManager transactionManager,
                                  ItemReader<CuentaAnual> cuentaAnualReader,
                                  ItemProcessor<CuentaAnual, CuentaAnual> cuentaAnualItemProcessor,
                                  ItemWriter<CuentaAnual> cuentaAnualWriter) {
        return new StepBuilder("cuentasAnualesStep", jobRepository)
                .<CuentaAnual, CuentaAnual>chunk(10, transactionManager)
                .reader(cuentaAnualReader)
                .processor(cuentaAnualItemProcessor)
                .writer(cuentaAnualWriter)
                .build();
    }

    @Bean
    public Job estadosCuentaAnualesJob(JobRepository jobRepository, Step cuentasAnualesStep) {
        return new JobBuilder("estadosCuentaAnualesJob", jobRepository)
                .start(cuentasAnualesStep)
                .build();
    }

    // ============================================
    // JOBS ADICIONALES PARA DETALLES
    // ============================================

    // Job para procesar detalles de intereses calculados
    @Bean
    public Step interesesDetalleStep(JobRepository jobRepository,
                                   JdbcTransactionManager transactionManager,
                                   ItemReader<Cuenta> cuentaReader,
                                   ItemProcessor<Cuenta, InteresCalculado> interesCalculadoItemProcessor,
                                   ItemWriter<InteresCalculado> interesCalculadoWriter) {
        return new StepBuilder("interesesDetalleStep", jobRepository)
                .<Cuenta, InteresCalculado>chunk(10, transactionManager)
                .reader(cuentaReader)
                .processor(interesCalculadoItemProcessor)
                .writer(interesCalculadoWriter)
                .build();
    }

    @Bean
    public Job interesesDetalleJob(JobRepository jobRepository, Step interesesDetalleStep) {
        return new JobBuilder("interesesDetalleJob", jobRepository)
                .start(interesesDetalleStep)
                .build();
    }

    // Job para procesar estados de cuenta detallados
    @Bean
    public Step estadosDetalleStep(JobRepository jobRepository,
                                 JdbcTransactionManager transactionManager,
                                 ItemReader<CuentaAnual> cuentaAnualReader,
                                 ItemProcessor<CuentaAnual, EstadoCuentaAnual> estadoCuentaAnualItemProcessor,
                                 ItemWriter<EstadoCuentaAnual> estadoCuentaAnualWriter) {
        return new StepBuilder("estadosDetalleStep", jobRepository)
                .<CuentaAnual, EstadoCuentaAnual>chunk(10, transactionManager)
                .reader(cuentaAnualReader)
                .processor(estadoCuentaAnualItemProcessor)
                .writer(estadoCuentaAnualWriter)
                .build();
    }

    @Bean
    public Job estadosDetalleJob(JobRepository jobRepository, Step estadosDetalleStep) {
        return new JobBuilder("estadosDetalleJob", jobRepository)
                .start(estadosDetalleStep)
                .build();
    }

    // Job para procesar anomal√≠as de transacciones
    @Bean
    public Step anomaliasStep(JobRepository jobRepository,
                             JdbcTransactionManager transactionManager,
                             ItemReader<Transaccion> anomaliaTransaccionReader,
                             ItemProcessor<Transaccion, AnomaliaTransaccion> simpleAnomaliaProcessor,
                             ItemWriter<AnomaliaTransaccion> anomaliaTransaccionWriter) {
        return new StepBuilder("anomaliasStep", jobRepository)
                .<Transaccion, AnomaliaTransaccion>chunk(10, transactionManager)
                .reader(anomaliaTransaccionReader)
                .processor(simpleAnomaliaProcessor)
                .writer(anomaliaTransaccionWriter)
                .build();
    }

    @Bean
    public Job anomaliasJob(JobRepository jobRepository, Step anomaliasStep) {
        return new JobBuilder("anomaliasJob", jobRepository)
                .start(anomaliasStep)
                .build();
    }

    // ============================================
    // JOBS AVANZADOS PARA DETECCI√ìN DE ANOMAL√çAS CON POL√çTICAS DE REINTENTO Y OMISI√ìN
    // ============================================
    
    // Step para detectar TODAS las anomal√≠as en transacciones con ESCALAMIENTO PARALELO
    @Bean
    public Step deteccionAnomal√≠asAvanzadasStep(JobRepository jobRepository,
                                               JdbcTransactionManager transactionManager,
                                               ItemReader<Transaccion> todasLasTransaccionesReader,
                                               ItemProcessor<Transaccion, java.util.List<AnomaliaTransaccion>> detectarAnomal√≠asLegacyProcessor,
                                               org.springframework.batch.item.ItemWriter<java.util.List<AnomaliaTransaccion>> anomaliaListWriter,
                                               org.springframework.retry.RetryPolicy transaccionesRetryPolicy,
                                               org.springframework.batch.core.step.skip.SkipPolicy transaccionesSkipPolicy,
                                               org.springframework.batch.core.StepExecutionListener faultToleranceListener,
                                               @Qualifier("anomalyTaskExecutor") TaskExecutor anomalyTaskExecutor,
                                               @Qualifier("optimizedChunkSize") Integer chunkSize) {
        
        System.out.println("=== CONFIGURANDO DETECCI√ìN ANOMAL√çAS CON ESCALAMIENTO PARALELO ===");
        System.out.println("   TaskExecutor: " + anomalyTaskExecutor.getClass().getSimpleName());
        System.out.println("   Chunk Size: " + chunkSize + " registros");
        System.out.println("   Hilos paralelos: 3 (escalamiento hasta 6)");
        System.out.println("   Detecci√≥n inteligente de anomal√≠as");
        
        return new StepBuilder("deteccionAnomal√≠asAvanzadasStep", jobRepository)
                .<Transaccion, java.util.List<AnomaliaTransaccion>>chunk(chunkSize, transactionManager)
                .reader(todasLasTransaccionesReader)
                .processor(detectarAnomal√≠asLegacyProcessor)
                .writer(anomaliaListWriter)
                // Escalamiento paralelo para an√°lisis de anomal√≠as
                .taskExecutor(anomalyTaskExecutor)
                // üõ°Ô∏è POL√çTICAS PERSONALIZADAS DE TOLERANCIA A FALLOS
                .faultTolerant()
                .retryPolicy(transaccionesRetryPolicy) // Pol√≠tica de reintento personalizada
                .skipPolicy(transaccionesSkipPolicy)   // Pol√≠tica de omisi√≥n inteligente
                .listener(faultToleranceListener)      // Monitoreo y logging avanzado
                .build();
    }

    @Bean
    public Job deteccionAnomal√≠asAvanzadasJob(JobRepository jobRepository, Step deteccionAnomal√≠asAvanzadasStep) {
        return new JobBuilder("deteccionAnomal√≠asAvanzadasJob", jobRepository)
                .start(deteccionAnomal√≠asAvanzadasStep)
                .build();
    }

    // Step para detectar anomal√≠as y duplicados en cuentas
    @Bean
    public Step deteccionAnomal√≠asCuentasStep(JobRepository jobRepository,
                                             JdbcTransactionManager transactionManager,
                                             ItemReader<Cuenta> todasLasCuentasReader,
                                             ItemProcessor<Cuenta, java.util.List<AnomaliaTransaccion>> detectarAnomaliasCuentasProcessor,
                                             org.springframework.batch.item.ItemWriter<java.util.List<AnomaliaTransaccion>> anomaliaListWriter,
                                             org.springframework.retry.RetryPolicy cuentasRetryPolicy,
                                             org.springframework.batch.core.step.skip.SkipPolicy cuentasSkipPolicy,
                                             org.springframework.batch.core.StepExecutionListener faultToleranceListener) {
        return new StepBuilder("deteccionAnomal√≠asCuentasStep", jobRepository)
                .<Cuenta, java.util.List<AnomaliaTransaccion>>chunk(5, transactionManager)
                .reader(todasLasCuentasReader)
                .processor(detectarAnomaliasCuentasProcessor)
                .writer(anomaliaListWriter)
                // üõ°Ô∏è POL√çTICAS PERSONALIZADAS PARA CUENTAS (M√ÅS ESTRICTAS)
                .faultTolerant()
                .retryPolicy(cuentasRetryPolicy)     // Reintentos m√°s conservadores
                .skipPolicy(cuentasSkipPolicy)       // Omisiones m√°s estrictas
                .listener(faultToleranceListener)    // Monitoreo detallado
                .build();
    }

    @Bean
    public Job deteccionAnomal√≠asCuentasJob(JobRepository jobRepository, Step deteccionAnomal√≠asCuentasStep) {
        return new JobBuilder("deteccionAnomal√≠asCuentasJob", jobRepository)
                .start(deteccionAnomal√≠asCuentasStep)
                .build();
    }

    // ============================================
    // JOBS CON PARTICIONES - NUEVA FUNCIONALIDAD
    // ============================================
    
    /**
     * Step worker (esclavo) para procesamiento particionado de transacciones.
     * Este step procesa una partici√≥n espec√≠fica de transacciones.
     */
    @Bean
    public Step partitionedTransaccionWorkerStep(JobRepository jobRepository,
                                                  JdbcTransactionManager transactionManager,
                                                  ItemReader<Transaccion> partitionedTransaccionReader,
                                                  ItemProcessor<Transaccion, Transaccion> transaccionItemProcessor,
                                                  ItemWriter<Transaccion> transaccionWriter,
                                                  ScalingPerformanceListener scalingPerformanceListener,
                                                  @Qualifier("optimizedChunkSize") Integer chunkSize) {
        
        System.out.println("‚öôÔ∏è  Configurando Worker Step para Transacciones Particionadas");
        System.out.println("   ‚Ä¢ Chunk Size: " + chunkSize);
        System.out.println("   ‚Ä¢ Listener: PartitionPerformanceListener activo");
        
        return new StepBuilder("partitionedTransaccionWorkerStep", jobRepository)
                .<Transaccion, Transaccion>chunk(chunkSize, transactionManager)
                .reader(partitionedTransaccionReader) // Se resuelve din√°micamente por @StepScope
                .processor(transaccionItemProcessor)
                .writer(transaccionWriter)
                .listener(scalingPerformanceListener)
                .build();
    }
    
    /**
     * Step maestro para procesamiento particionado de transacciones.
     * Coordina m√∫ltiples particiones utilizando el partitioner y handler.
     */
    @Bean
    public Step partitionedTransaccionMasterStep(JobRepository jobRepository,
                                                  BankDataPartitioner bankDataPartitioner,
                                                  @Qualifier("partitionCoordinatorTaskExecutor") TaskExecutor coordinatorTaskExecutor,
                                                  Step partitionedTransaccionWorkerStep) {
        
        System.out.println("üéØ Configurando Master Step para Transacciones Particionadas:");
        System.out.println("   ‚Ä¢ Partitioner: BankDataPartitioner");
        System.out.println("   ‚Ä¢ Handler: PartitionCoordinator (4 particiones)");
        System.out.println("   ‚Ä¢ Worker: partitionedTransaccionWorkerStep (SIN multi-threading interno)");
        System.out.println("   ‚Ä¢ Estrategia: DISTRIBUCI√ìN PURA");
        
        // Crear PartitionHandler inline con coordinator simple
        PartitionHandler partitionHandler = PartitionConfig.createTransactionPartitionHandler(coordinatorTaskExecutor, partitionedTransaccionWorkerStep);
        
        return new StepBuilder("partitionedTransaccionMasterStep", jobRepository)
                .partitioner("partitionedTransaccionWorkerStep", bankDataPartitioner)
                .partitionHandler(partitionHandler)
                .step(partitionedTransaccionWorkerStep)
                .build();
    }
    
    /**
     * Job para procesamiento de transacciones usando particiones.
     */
    @Bean
    public Job particionesTransaccionesJob(JobRepository jobRepository, 
                                           Step partitionedTransaccionMasterStep) {
        System.out.println("\nüöÄ CREANDO JOB PARTICIONADO: TRANSACCIONES DISTRIBUIDAS");
        System.out.println("   üìä Estrategia: 4 particiones autom√°ticas por rango de ID");
        System.out.println("   üîÑ TaskExecutor: partitionCoordinatorTaskExecutor (1 hilo por partition)");
        System.out.println("   üéØ Procesamiento: SECUENCIAL dentro de cada partici√≥n");
        System.out.println("   üìà Escalabilidad: Distribuci√≥n geogr√°fica/temporal");
        
        return new JobBuilder("particionesTransaccionesJob", jobRepository)
                .start(partitionedTransaccionMasterStep)
                .build();
    }
    
    /**
     * Step worker para procesamiento particionado de cuentas.
     */
    @Bean
    public Step partitionedCuentaWorkerStep(JobRepository jobRepository,
                                           JdbcTransactionManager transactionManager,
                                           ItemReader<Cuenta> partitionedCuentaReader,
                                           ItemProcessor<Cuenta, Cuenta> interesesItemProcessor,
                                           ItemWriter<Cuenta> cuentaWriter,
                                           ScalingPerformanceListener scalingPerformanceListener,
                                           @Qualifier("optimizedChunkSize") Integer chunkSize) {
        
        System.out.println("‚öôÔ∏è  Configurando Worker Step para Cuentas Particionadas");
        
        return new StepBuilder("partitionedCuentaWorkerStep", jobRepository)
                .<Cuenta, Cuenta>chunk(chunkSize, transactionManager)
                .reader(partitionedCuentaReader) // Se resuelve din√°micamente por @StepScope
                .processor(interesesItemProcessor)
                .writer(cuentaWriter)
                .listener(scalingPerformanceListener)
                .build();
    }
    
    /**
     * Step maestro para procesamiento particionado de cuentas.
     */
    @Bean
    public Step partitionedCuentaMasterStep(JobRepository jobRepository,
                                           BankDataPartitioner bankDataPartitioner,
                                           @Qualifier("partitionCoordinatorTaskExecutor") TaskExecutor coordinatorTaskExecutor,
                                           Step partitionedCuentaWorkerStep) {
        
        System.out.println("üéØ Configurando Master Step para Cuentas Particionadas:");
        System.out.println("   ‚Ä¢ Handler: PartitionCoordinator (3 particiones)");
        System.out.println("   ‚Ä¢ Estrategia: DISTRIBUCI√ìN PURA SIN multi-threading interno");
        
        // Crear PartitionHandler inline con coordinator simple
        PartitionHandler partitionHandler = PartitionConfig.createAccountPartitionHandler(coordinatorTaskExecutor, partitionedCuentaWorkerStep);
        
        return new StepBuilder("partitionedCuentaMasterStep", jobRepository)
                .partitioner("partitionedCuentaWorkerStep", bankDataPartitioner)
                .partitionHandler(partitionHandler)
                .step(partitionedCuentaWorkerStep)
                .build();
    }
    
    /**
     * Job para procesamiento de cuentas usando particiones.
     */
    @Bean
    public Job particionesCuentasJob(JobRepository jobRepository, 
                                    Step partitionedCuentaMasterStep) {
        System.out.println("üöÄ CREANDO JOB PARTICIONADO: CUENTAS ANUALES DISTRIBUIDAS");
        System.out.println("   ‚öôÔ∏è Sistema de Particiones Activo");
        System.out.println("   üìä Distribuci√≥n: 3 Particiones (SIN multi-threading interno)");
        System.out.println("   üéØ Estrategia: DISTRIBUCI√ìN GEOGR√ÅFICA O TEMPORAL");
        System.out.println("   üíæ Escalable para millones de registros");
        System.out.println("   -------------------------------------------");
        
        return new JobBuilder("particionesCuentasJob", jobRepository)
                .start(partitionedCuentaMasterStep)
                .build();
    }
    
    /**
     * Step worker para detecci√≥n particionada de anomal√≠as.
     */
    @Bean
    public Step partitionedAnomaliaWorkerStep(JobRepository jobRepository,
                                             JdbcTransactionManager transactionManager,
                                             ItemReader<Transaccion> partitionedAnomaliaTransaccionReader,
                                             ItemProcessor<Transaccion, java.util.List<AnomaliaTransaccion>> detectarAnomal√≠asLegacyProcessor,
                                             org.springframework.batch.item.ItemWriter<java.util.List<AnomaliaTransaccion>> anomaliaListWriter,
                                             ScalingPerformanceListener scalingPerformanceListener) {
        
        System.out.println("üö® Configurando Worker Step para Anomal√≠as Particionadas");
        
        return new StepBuilder("partitionedAnomaliaWorkerStep", jobRepository)
                .<Transaccion, java.util.List<AnomaliaTransaccion>>chunk(3, transactionManager) // Chunks peque√±os para anomal√≠as
                .reader(partitionedAnomaliaTransaccionReader) // Se resuelve din√°micamente por @StepScope
                .processor(detectarAnomal√≠asLegacyProcessor)
                .writer(anomaliaListWriter)
                .listener(scalingPerformanceListener)
                .build();
    }
    
    /**
     * Step maestro para detecci√≥n particionada de anomal√≠as.
     */
    @Bean
    public Step partitionedAnomaliaMasterStep(JobRepository jobRepository,
                                             BankDataPartitioner bankDataPartitioner,
                                             @Qualifier("partitionCoordinatorTaskExecutor") TaskExecutor coordinatorTaskExecutor,
                                             Step partitionedAnomaliaWorkerStep) {
        
        System.out.println("üéØ Configurando Master Step para Anomal√≠as Particionadas:");
        System.out.println("   ‚Ä¢ Handler: PartitionCoordinator (6 particiones)");
        System.out.println("   ‚Ä¢ Estrategia: DISTRIBUCI√ìN POR TIPO DE ANOMAL√çA");
        
        // Crear PartitionHandler inline con coordinator simple
        PartitionHandler partitionHandler = PartitionConfig.createAnomalyPartitionHandler(coordinatorTaskExecutor, partitionedAnomaliaWorkerStep);
        
        return new StepBuilder("partitionedAnomaliaMasterStep", jobRepository)
                .partitioner("partitionedAnomaliaWorkerStep", bankDataPartitioner)
                .partitionHandler(partitionHandler)
                .step(partitionedAnomaliaWorkerStep)
                .build();
    }
    
    /**
     * Job para detecci√≥n de anomal√≠as usando particiones.
     */
    @Bean
    public Job particionesAnomaliasJob(JobRepository jobRepository, 
                                      Step partitionedAnomaliaMasterStep) {
        System.out.println("üöÄ CREANDO JOB PARTICIONADO: DETECCI√ìN DE ANOMAL√çAS AVANZADA");
        System.out.println("   üö® Sistema de Detecci√≥n Distribuido");
        System.out.println("   üìä Distribuci√≥n: 6 Particiones (SIN multi-threading interno)");
        System.out.println("   üéØ Estrategia: DISTRIBUCI√ìN POR TIPO DE ANOMAL√çA");
        System.out.println("   üîç Escalable para an√°lisis masivos de transacciones");
        System.out.println("   -------------------------------------------");
        
        return new JobBuilder("particionesAnomaliasJob", jobRepository)
                .start(partitionedAnomaliaMasterStep)
                .build();
    }
}
